{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3c0a575",
   "metadata": {},
   "source": [
    "# 答疑解惑"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b78f79",
   "metadata": {},
   "source": [
    "## make_dot\n",
    "\n",
    "`make_dot` 是 **Graphviz** 库中的一个函数（通常通过 `torchviz` 或 `graphviz` 包提供），用于可视化计算图（如神经网络结构）。它能将模型的计算流程转换为图形表示，便于理解模型的结构和数据流向。\n",
    "\n",
    "\n",
    "### **一、`make_dot` 函数的基本用法**\n",
    "#### 1. **核心功能**\n",
    "- 将 PyTorch/TensorFlow 模型的计算图转换为可视化图形。\n",
    "- 通过节点（nodes）表示张量（Tensors）或操作（Operations），边（edges）表示数据流向。\n",
    "\n",
    "#### 2. **安装依赖**\n",
    "```bash\n",
    "pip install torchviz graphviz\n",
    "```\n",
    "注意：需先安装 Graphviz 系统工具（如 macOS 可用 `brew install graphviz`）。\n",
    "\n",
    "\n",
    "### **二、解释 `clf_view = make_dot(y, params=...)`**\n",
    "#### 1. **代码功能**\n",
    "这行代码使用 `make_dot` 可视化一个分类器（`clf`）的计算图，包含：\n",
    "- `y`：模型的输出张量（如预测结果）。\n",
    "- `params`：需要显示的参数（包括模型权重和输入数据）。\n",
    "\n",
    "#### 2. **关键参数解析**\n",
    "- **`y`**：计算图的输出节点（通常是损失函数或预测值）。\n",
    "- **`params`**：一个字典，包含需要可视化的参数：\n",
    "  ```python\n",
    "  dict(list(clf.named_parameters()) + [(\"x\", input_sample)])\n",
    "  ```\n",
    "  - `clf.named_parameters()`：获取模型的所有参数（如权重、偏置）。\n",
    "  - `[(\"x\", input_sample)]`：手动添加输入样本 `input_sample`，命名为 `\"x\"`。\n",
    "  - **合并参数**：将模型参数和输入数据合并为一个字典。\n",
    "\n",
    "#### 3. **完整示例**\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchviz import make_dot\n",
    "\n",
    "# 定义一个简单的分类器\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)\n",
    "        self.fc2 = nn.Linear(5, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return torch.sigmoid(self.fc2(x))\n",
    "\n",
    "# 创建模型和输入\n",
    "clf = SimpleClassifier()\n",
    "input_sample = torch.randn(1, 10, requires_grad=True)\n",
    "y = clf(input_sample)  # 前向传播\n",
    "\n",
    "# 可视化计算图\n",
    "clf_view = make_dot(y, params=dict(list(clf.named_parameters()) + [(\"x\", input_sample)]))\n",
    "clf_view.render(\"classifier_graph\", format=\"png\", cleanup=True)\n",
    "```\n",
    "\n",
    "#### 4. **可视化效果**\n",
    "- **节点**：包括输入 `x`、中间层输出、模型参数（`fc1.weight`、`fc1.bias` 等）。\n",
    "- **边**：表示数据流动方向（如从 `x` 到 `fc1` 再到 `fc2`）。\n",
    "\n",
    "\n",
    "### **三、注意事项**\n",
    "1. **requires_grad=True**：\n",
    "   - 若要显示某个张量（如输入），需确保其 `requires_grad=True`（示例中 `input_sample` 已设置）。\n",
    "\n",
    "2. **保存图形**：\n",
    "   - `dot.render(\"filename\", format=\"png\")`：保存为 PNG 图片。\n",
    "   - `dot.view()`：直接打开预览（需系统支持）。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79a253ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchviz in /opt/miniconda3/envs/LEEDL/lib/python3.12/site-packages (0.0.3)\n",
      "Requirement already satisfied: graphviz in /opt/miniconda3/envs/LEEDL/lib/python3.12/site-packages (0.20.3)\n",
      "Requirement already satisfied: torch in /opt/miniconda3/envs/LEEDL/lib/python3.12/site-packages (from torchviz) (2.7.1)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/envs/LEEDL/lib/python3.12/site-packages (from torch->torchviz) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/miniconda3/envs/LEEDL/lib/python3.12/site-packages (from torch->torchviz) (4.14.0)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/envs/LEEDL/lib/python3.12/site-packages (from torch->torchviz) (78.1.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/miniconda3/envs/LEEDL/lib/python3.12/site-packages (from torch->torchviz) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/miniconda3/envs/LEEDL/lib/python3.12/site-packages (from torch->torchviz) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/envs/LEEDL/lib/python3.12/site-packages (from torch->torchviz) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/miniconda3/envs/LEEDL/lib/python3.12/site-packages (from torch->torchviz) (2025.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/envs/LEEDL/lib/python3.12/site-packages (from sympy>=1.13.3->torch->torchviz) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/envs/LEEDL/lib/python3.12/site-packages (from jinja2->torch->torchviz) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchviz graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6567d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dot - graphviz version 12.2.1 (20241206.2353)\n"
     ]
    }
   ],
   "source": [
    "!dot -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17484540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"108pt\" height=\"337pt\" viewBox=\"0.00 0.00 108.00 337.25\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 333.25)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-333.25 104,-333.25 104,4 -4,4\"/>\n",
       "<!-- 5026175632 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>5026175632</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"77,-32.75 23,-32.75 23,0 77,0 77,-32.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-7.25\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n",
       "</g>\n",
       "<!-- 5012332576 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>5012332576</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"97,-89.5 3,-89.5 3,-68.75 97,-68.75 97,-89.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-76\" font-family=\"monospace\" font-size=\"10.00\">MeanBackward0</text>\n",
       "</g>\n",
       "<!-- 5012332576&#45;&gt;5026175632 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>5012332576-&gt;5026175632</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50,-68.36C50,-61.89 50,-53.05 50,-44.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-44.55 50,-34.55 46.5,-44.55 53.5,-44.55\"/>\n",
       "</g>\n",
       "<!-- 5010089552 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>5010089552</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"94,-146.25 6,-146.25 6,-125.5 94,-125.5 94,-146.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-132.75\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 5010089552&#45;&gt;5012332576 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>5010089552-&gt;5012332576</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50,-125.09C50,-118.47 50,-109.47 50,-101.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-101.34 50,-91.34 46.5,-101.34 53.5,-101.34\"/>\n",
       "</g>\n",
       "<!-- 5010089984 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>5010089984</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"94,-203 6,-203 6,-182.25 94,-182.25 94,-203\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n",
       "</g>\n",
       "<!-- 5010089984&#45;&gt;5010089552 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>5010089984-&gt;5010089552</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50,-181.84C50,-175.22 50,-166.22 50,-158.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-158.09 50,-148.09 46.5,-158.09 53.5,-158.09\"/>\n",
       "</g>\n",
       "<!-- 5010085424 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>5010085424</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"100,-259.75 0,-259.75 0,-239 100,-239 100,-259.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-246.25\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 5010085424&#45;&gt;5010089984 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>5010085424-&gt;5010089984</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50,-238.59C50,-231.97 50,-222.97 50,-214.77\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-214.84 50,-204.84 46.5,-214.84 53.5,-214.84\"/>\n",
       "</g>\n",
       "<!-- 5026060784 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5026060784</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"82,-329.25 18,-329.25 18,-295.75 82,-295.75 82,-329.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-315.75\" font-family=\"monospace\" font-size=\"10.00\">x</text>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-303\" font-family=\"monospace\" font-size=\"10.00\"> (1, 10)</text>\n",
       "</g>\n",
       "<!-- 5026060784&#45;&gt;5010085424 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>5026060784-&gt;5010085424</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50,-295.44C50,-288.1 50,-279.32 50,-271.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-271.73 50,-261.73 46.5,-271.73 53.5,-271.73\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torchviz import make_dot\n",
    "from IPython.display import display, SVG\n",
    "\n",
    "# 定义一个简单模型\n",
    "x = torch.randn(1, 10, requires_grad=True)\n",
    "y = x ** 2 + 3\n",
    "y = y.mean()\n",
    "\n",
    "# 创建可视化\n",
    "dot = make_dot(y, params={\"x\": x})\n",
    "# dot.render(\"simple_graph\", format=\"png\", cleanup=True)\n",
    "display(SVG(dot.pipe(format=\"svg\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7600a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"414pt\" height=\"489pt\" viewBox=\"0.00 0.00 414.00 489.00\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 485)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-485 410,-485 410,4 -4,4\"/>\n",
       "<!-- 5026172192 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>5026172192</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"225,-32.75 167,-32.75 167,0 225,0 225,-32.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"196\" y=\"-7.25\" font-family=\"monospace\" font-size=\"10.00\"> (1, 1)</text>\n",
       "</g>\n",
       "<!-- 5010089984 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>5010089984</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"252,-89.5 140,-89.5 140,-68.75 252,-68.75 252,-89.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"196\" y=\"-76\" font-family=\"monospace\" font-size=\"10.00\">SigmoidBackward0</text>\n",
       "</g>\n",
       "<!-- 5010089984&#45;&gt;5026172192 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>5010089984-&gt;5026172192</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M196,-68.36C196,-61.89 196,-53.05 196,-44.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"199.5,-44.55 196,-34.55 192.5,-44.55 199.5,-44.55\"/>\n",
       "</g>\n",
       "<!-- 5010080960 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>5010080960</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"246,-146.25 146,-146.25 146,-125.5 246,-125.5 246,-146.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"196\" y=\"-132.75\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n",
       "</g>\n",
       "<!-- 5010080960&#45;&gt;5010089984 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>5010080960-&gt;5010089984</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M196,-125.09C196,-118.47 196,-109.47 196,-101.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"199.5,-101.34 196,-91.34 192.5,-101.34 199.5,-101.34\"/>\n",
       "</g>\n",
       "<!-- 5010090512 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>5010090512</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"131,-203 31,-203 31,-182.25 131,-182.25 131,-203\"/>\n",
       "<text text-anchor=\"middle\" x=\"81\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 5010090512&#45;&gt;5010080960 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>5010090512-&gt;5010080960</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M101.56,-181.84C119.3,-173.39 145.18,-161.07 165.37,-151.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"166.73,-154.69 174.25,-147.23 163.72,-148.37 166.73,-154.69\"/>\n",
       "</g>\n",
       "<!-- 5026172912 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>5026172912</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"113,-272.5 49,-272.5 49,-239 113,-239 113,-272.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"81\" y=\"-259\" font-family=\"monospace\" font-size=\"10.00\">fc2.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"81\" y=\"-246.25\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 5026172912&#45;&gt;5010090512 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>5026172912-&gt;5010090512</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M81,-238.69C81,-231.35 81,-222.57 81,-214.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"84.5,-214.98 81,-204.98 77.5,-214.98 84.5,-214.98\"/>\n",
       "</g>\n",
       "<!-- 5010086000 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5010086000</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"243,-203 149,-203 149,-182.25 243,-182.25 243,-203\"/>\n",
       "<text text-anchor=\"middle\" x=\"196\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 5010086000&#45;&gt;5010080960 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>5010086000-&gt;5010080960</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M196,-181.84C196,-175.22 196,-166.22 196,-158.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"199.5,-158.09 196,-148.09 192.5,-158.09 199.5,-158.09\"/>\n",
       "</g>\n",
       "<!-- 5010080144 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>5010080144</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"238,-266.12 138,-266.12 138,-245.38 238,-245.38 238,-266.12\"/>\n",
       "<text text-anchor=\"middle\" x=\"188\" y=\"-252.62\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n",
       "</g>\n",
       "<!-- 5010080144&#45;&gt;5010086000 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>5010080144-&gt;5010086000</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M189.29,-244.93C190.35,-236.77 191.91,-224.88 193.25,-214.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"196.72,-215.09 194.55,-204.72 189.78,-214.18 196.72,-215.09\"/>\n",
       "</g>\n",
       "<!-- 5010084176 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>5010084176</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"100,-335.62 0,-335.62 0,-314.88 100,-314.88 100,-335.62\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-322.12\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 5010084176&#45;&gt;5010080144 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5010084176-&gt;5010080144</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M70.07,-314.43C93.06,-303.19 131,-284.63 157.62,-271.61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"159.1,-274.78 166.55,-267.24 156.03,-268.49 159.1,-274.78\"/>\n",
       "</g>\n",
       "<!-- 5026173152 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>5026173152</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"82,-411.5 18,-411.5 18,-378 82,-378 82,-411.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-398\" font-family=\"monospace\" font-size=\"10.00\">fc1.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-385.25\" font-family=\"monospace\" font-size=\"10.00\"> (5)</text>\n",
       "</g>\n",
       "<!-- 5026173152&#45;&gt;5010084176 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>5026173152-&gt;5010084176</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50,-377.75C50,-368.65 50,-357.14 50,-347.32\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-347.59 50,-337.59 46.5,-347.59 53.5,-347.59\"/>\n",
       "</g>\n",
       "<!-- 5010080288 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>5010080288</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"218,-335.62 118,-335.62 118,-314.88 218,-314.88 218,-335.62\"/>\n",
       "<text text-anchor=\"middle\" x=\"168\" y=\"-322.12\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 5010080288&#45;&gt;5010080144 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>5010080288-&gt;5010080144</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M170.87,-314.58C173.75,-304.85 178.28,-289.57 181.96,-277.15\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"185.22,-278.44 184.71,-267.85 178.51,-276.45 185.22,-278.44\"/>\n",
       "</g>\n",
       "<!-- 5026173312 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>5026173312</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"200,-411.5 136,-411.5 136,-378 200,-378 200,-411.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"168\" y=\"-398\" font-family=\"monospace\" font-size=\"10.00\">x</text>\n",
       "<text text-anchor=\"middle\" x=\"168\" y=\"-385.25\" font-family=\"monospace\" font-size=\"10.00\"> (1, 10)</text>\n",
       "</g>\n",
       "<!-- 5026173312&#45;&gt;5010080288 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>5026173312-&gt;5010080288</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M168,-377.75C168,-368.65 168,-357.14 168,-347.32\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"171.5,-347.59 168,-337.59 164.5,-347.59 171.5,-347.59\"/>\n",
       "</g>\n",
       "<!-- 5010083504 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>5010083504</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"312,-335.62 236,-335.62 236,-314.88 312,-314.88 312,-335.62\"/>\n",
       "<text text-anchor=\"middle\" x=\"274\" y=\"-322.12\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n",
       "</g>\n",
       "<!-- 5010083504&#45;&gt;5010080144 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>5010083504-&gt;5010080144</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M261.68,-314.58C248.09,-303.91 225.97,-286.55 209.51,-273.63\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"211.8,-270.98 201.77,-267.56 207.47,-276.48 211.8,-270.98\"/>\n",
       "</g>\n",
       "<!-- 5010080000 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>5010080000</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"324,-405.12 224,-405.12 224,-384.38 324,-384.38 324,-405.12\"/>\n",
       "<text text-anchor=\"middle\" x=\"274\" y=\"-391.62\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 5010080000&#45;&gt;5010083504 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>5010080000-&gt;5010083504</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M274,-384.08C274,-374.46 274,-359.38 274,-347.04\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"277.5,-347.42 274,-337.42 270.5,-347.42 277.5,-347.42\"/>\n",
       "</g>\n",
       "<!-- 5026173072 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>5026173072</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"312,-481 236,-481 236,-447.5 312,-447.5 312,-481\"/>\n",
       "<text text-anchor=\"middle\" x=\"274\" y=\"-467.5\" font-family=\"monospace\" font-size=\"10.00\">fc1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"274\" y=\"-454.75\" font-family=\"monospace\" font-size=\"10.00\"> (5, 10)</text>\n",
       "</g>\n",
       "<!-- 5026173072&#45;&gt;5010080000 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>5026173072-&gt;5010080000</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M274,-447.25C274,-438.15 274,-426.64 274,-416.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"277.5,-417.09 274,-407.09 270.5,-417.09 277.5,-417.09\"/>\n",
       "</g>\n",
       "<!-- 5010093536 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>5010093536</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"361,-203 285,-203 285,-182.25 361,-182.25 361,-203\"/>\n",
       "<text text-anchor=\"middle\" x=\"323\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n",
       "</g>\n",
       "<!-- 5010093536&#45;&gt;5010080960 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>5010093536-&gt;5010080960</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M300.29,-181.84C280.43,-173.27 251.33,-160.73 228.91,-151.06\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"230.47,-147.92 219.9,-147.18 227.7,-154.35 230.47,-147.92\"/>\n",
       "</g>\n",
       "<!-- 5010080816 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>5010080816</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"397,-266.12 297,-266.12 297,-245.38 397,-245.38 397,-266.12\"/>\n",
       "<text text-anchor=\"middle\" x=\"347\" y=\"-252.62\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 5010080816&#45;&gt;5010093536 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>5010080816-&gt;5010093536</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M343.14,-244.93C339.87,-236.59 335.07,-224.36 330.97,-213.93\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"334.23,-212.66 327.32,-204.63 327.72,-215.22 334.23,-212.66\"/>\n",
       "</g>\n",
       "<!-- 5026176192 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>5026176192</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"406,-342 330,-342 330,-308.5 406,-308.5 406,-342\"/>\n",
       "<text text-anchor=\"middle\" x=\"368\" y=\"-328.5\" font-family=\"monospace\" font-size=\"10.00\">fc2.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"368\" y=\"-315.75\" font-family=\"monospace\" font-size=\"10.00\"> (1, 5)</text>\n",
       "</g>\n",
       "<!-- 5026176192&#45;&gt;5010080816 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>5026176192-&gt;5010080816</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M363.02,-308.25C360.16,-299.05 356.53,-287.39 353.45,-277.49\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"356.82,-276.53 350.51,-268.02 350.13,-278.61 356.82,-276.53\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchviz import make_dot\n",
    "from IPython.display import display, SVG\n",
    "\n",
    "# 定义一个简单的分类器\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)\n",
    "        self.fc2 = nn.Linear(5, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return torch.sigmoid(self.fc2(x))\n",
    "\n",
    "# 创建模型和输入\n",
    "clf = SimpleClassifier()\n",
    "input_sample = torch.randn(1, 10, requires_grad=True)\n",
    "y = clf(input_sample)  # 前向传播\n",
    "\n",
    "# 可视化计算图\n",
    "clf_view = make_dot(y, params=dict(list(clf.named_parameters()) + [(\"x\", input_sample)]))\n",
    "# clf_view.view()\n",
    "# 转换为 SVG 格式并显示\n",
    "svg = clf_view.pipe(format='svg')\n",
    "display(SVG(svg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd33c7b",
   "metadata": {},
   "source": [
    "## np.random.choice()\n",
    "\n",
    "np.random.choice 是 NumPy 库中用于从给定数组或列表中随机抽样的函数。它可以根据指定的条件随机选择元素，常用于数据采样、随机实验设计等场景。\n",
    "\n",
    "一、np.random.choice 的基本用法\n",
    "核心参数\n",
    "```python\n",
    "np.random.choice(a, size=None, replace=True, p=None)\n",
    "```\n",
    "\n",
    "- a：输入的一维数组或整数 n（表示 range(n)）。\n",
    "- size：输出的样本大小（整数或元组）。\n",
    "- replace：是否允许重复抽样（True 表示有放回，False 表示无放回）。\n",
    "- p：可选参数，指定每个元素被选中的概率（数组，需与 a 长度一致且和为 1）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1183fb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 5 2]\n"
     ]
    }
   ],
   "source": [
    "# 示例 1：从数组中随机选择元素\n",
    "import numpy as np\n",
    "\n",
    "# 从一维数组中随机选出三个，允许重复\n",
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "sample = np.random.choice(arr, size=3, replace=True)\n",
    "print(sample) # 出现了重复的元素5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7118b070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 0]\n"
     ]
    }
   ],
   "source": [
    "# 示例 2：无放回抽样（不允许重复）\n",
    "# 从 0~4 中随机选择 3 个不重复的整数\n",
    "sample = np.random.choice(5, size=3, replace=False)\n",
    "print(sample)  # 可能输出：[2, 4, 0]（不重复）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "049712d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# 示例 3：指定概率分布\n",
    "# 按概率 p 抽样（元素 0 的概率为 0.1，元素 1 的概率为 0.6，元素 2 的概率为 0.3）\n",
    "sample = np.random.choice([0, 1, 2], size=5, p=[0.1, 0.6, 0.3])\n",
    "print(sample)  # 可能输出：[1, 1, 2, 1, 0]（1 出现的次数较多）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62c0cf9",
   "metadata": {},
   "source": [
    "## BatchNorm2d\n",
    "\n",
    "在卷积神经网络（CNN）中，BatchNorm2d（二维批量归一化）是一种常用的正则化技术，用于加速训练并提高模型稳定性。下面结合你提供的代码，详细解释其作用和原理。\n",
    "\n",
    "### 一、BatchNorm2d 的工作原理\n",
    "对于每个批次（Batch）的输入特征图，`BatchNorm2d` 独立对每个通道进行归一化，公式为：\n",
    "```\n",
    "y = γ * (x - μ) / √(σ² + ε) + β\n",
    "```\n",
    "- **μ**：批次内每个通道的均值。\n",
    "- **σ²**：批次内每个通道的方差。\n",
    "- **γ** 和 **β**：可学习的缩放因子和偏移量（模型参数）。\n",
    "- **ε**：小常数（如 `1e-5`），防止分母为零。\n",
    "\n",
    "### 二、结合代码示例解释\n",
    "在你的 CNN 中，每个卷积层后都跟着 `BatchNorm2d`：\n",
    "```python\n",
    "nn.Conv2d(3, 64, 3, 1, 1),  # 输入3通道，输出64通道\n",
    "nn.BatchNorm2d(64),         # 对64个通道分别归一化\n",
    "nn.ReLU(),\n",
    "```\n",
    "\n",
    "### 三、BatchNorm2d 的优势示例\n",
    "#### **1. 加速训练**\n",
    "假设没有 BatchNorm：\n",
    "- 深层网络中，前层参数的微小变化可能导致后层输入分布剧烈变化。\n",
    "- 学习率需要设置得很小，训练缓慢。\n",
    "\n",
    "加入 BatchNorm 后：\n",
    "- 每层输入分布更稳定，可使用更大学习率。\n",
    "- 实验表明，训练速度可提升 5-10 倍。\n",
    "\n",
    "#### **2. 提高泛化能力**\n",
    "- BatchNorm 引入了一定的随机性（批次统计量的波动），类似 Dropout 的正则化效果。\n",
    "- 在你的代码中，5 个 BatchNorm 层共同作用，使模型更健壮。\n",
    "\n",
    "#### **3. 缓解梯度问题**\n",
    "- 在深层 CNN 中，未归一化的激活值可能导致梯度消失或爆炸。\n",
    "- BatchNorm 保持数据分布在合理范围（如均值 0，方差 1），稳定梯度流。\n",
    "\n",
    "\n",
    "### 四、BatchNorm2d 的参数\n",
    "```python\n",
    "nn.BatchNorm2d(num_features, eps=1e-5, momentum=0.1, affine=True, track_running_stats=True)\n",
    "```\n",
    "- **num_features**：输入特征的通道数（如代码中的 64、128 等）。\n",
    "- **affine**：是否学习 `γ` 和 `β`（默认为 `True`）。\n",
    "- **track_running_stats**：是否跟踪训练时的均值和方差（用于推理阶段）。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb27e000",
   "metadata": {},
   "source": [
    "## acc = (pred.argmax(dim=-1) == y.to(device)).float().mean()\n",
    "\n",
    "这条语句用于计算分类任务中的**准确率（Accuracy）**，即模型预测正确的样本比例。我来拆解它的具体逻辑：\n",
    "\n",
    "\n",
    "### **一、代码逐行解析**\n",
    "```python\n",
    "acc = (pred.argmax(dim=-1) == y.to(device)).float().mean()\n",
    "```\n",
    "\n",
    "#### **1. `pred.argmax(dim=-1)`**\n",
    "- **`pred`**：模型的预测输出，通常是形状为 `[batch_size, num_classes]` 的张量。\n",
    "- **`argmax(dim=-1)`**：沿最后一个维度（类别维度）取最大值的索引，得到预测的类别标签。\n",
    "  - 例如：若 `pred` 是 `[[0.1, 0.8, 0.1], [0.7, 0.2, 0.1]]`，则 `argmax` 结果为 `[1, 0]`（对应类别索引）。\n",
    "\n",
    "#### **2. `y.to(device)`**\n",
    "- **`y`**：真实标签，通常是形状为 `[batch_size]` 的张量。\n",
    "- **`to(device)`**：将真实标签移动到与预测结果相同的设备（如GPU）上，确保比较操作能正常执行。\n",
    "\n",
    "#### **3. `pred.argmax(dim=-1) == y.to(device)`**\n",
    "- 比较预测标签与真实标签，得到一个布尔型张量，元素为 `True`（预测正确）或 `False`（预测错误）。\n",
    "  - 例如：若预测为 `[1, 0]`，真实标签为 `[1, 1]`，则结果为 `[True, False]`。\n",
    "\n",
    "#### **4. `.float().mean()`**\n",
    "- **`.float()`**：将布尔型张量转换为浮点型（`True` 变为 1.0，`False` 变为 0.0）。\n",
    "- **`.mean()`**：计算平均值，即预测正确的样本比例（准确率）。\n",
    "  - 例如：`[True, False]` 转换为 `[1.0, 0.0]`，平均值为 `0.5`（即50%准确率）。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd2bf97",
   "metadata": {},
   "source": [
    "## train_pbar = tqdm(train_loader, position=0, leave=True)\n",
    "\n",
    "这条语句使用 `tqdm` 库为数据加载器 `train_loader` 创建一个可视化的进度条，用于实时显示训练数据的加载和处理进度。以下是详细解释：\n",
    "\n",
    "\n",
    "### **一、`tqdm` 库的作用**\n",
    "`tqdm`（发音为 \"taqadum\"，阿拉伯语意为 \"进步\"）是 Python 中常用的进度条库，用于在循环中显示进度信息，提供直观的视觉反馈。尤其适用于：\n",
    "- 长时间运行的任务（如模型训练）。\n",
    "- 需要监控进度的迭代过程（如数据加载、批量处理）。\n",
    "\n",
    "\n",
    "### **二、代码解析**\n",
    "```python\n",
    "train_pbar = tqdm(train_loader, position=0, leave=True)\n",
    "```\n",
    "\n",
    "#### **1. `train_loader`**\n",
    "- **数据加载器**：通常是 PyTorch 的 `DataLoader` 对象，用于批量加载训练数据。\n",
    "- **示例**：假设 `train_loader` 包含 100 个批次，每个批次 32 个样本，则总样本数为 3200。\n",
    "\n",
    "#### **2. `tqdm(...)`**\n",
    "- **创建进度条**：将 `train_loader` 包装在 `tqdm` 中，返回一个可迭代的进度条对象 `train_pbar`。\n",
    "\n",
    "#### **3. `position=0`**\n",
    "- **进度条位置**：指定进度条在终端中的垂直位置（从 0 开始）。\n",
    "  - 若有多个进度条（如嵌套循环），可通过不同的 `position` 值控制其显示位置。\n",
    "\n",
    "#### **4. `leave=True`**\n",
    "- **训练结束后保留进度条**：训练完成后，进度条不会被清除，而是保留在终端中，便于查看最终状态。\n",
    "\n",
    "\n",
    "### **三、使用示例**\n",
    "#### **完整训练循环示例**：\n",
    "```python\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 假设 train_loader 已创建\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# 创建进度条\n",
    "train_pbar = tqdm(train_loader, position=0, leave=True)\n",
    "\n",
    "# 训练循环\n",
    "for batch_idx, (data, target) in enumerate(train_pbar):\n",
    "    # 更新进度条描述（可选）\n",
    "    train_pbar.set_description(f\"Epoch {epoch}\")\n",
    "    \n",
    "    # 前向传播、计算损失等\n",
    "    output = model(data)\n",
    "    loss = criterion(output, target)\n",
    "    \n",
    "    # 反向传播和优化\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 更新进度条的额外信息（可选）\n",
    "    train_pbar.set_postfix(loss=loss.item(), acc=accuracy.item())\n",
    "```\n",
    "\n",
    "#### **进度条显示效果**：\n",
    "```\n",
    "Epoch 1: 100%|██████████| 100/100 [00:30<00:00,  3.33it/s, loss=0.42, acc=0.87]\n",
    "```\n",
    "- **关键信息**：\n",
    "  - `100%|██████████|`：进度条可视化。\n",
    "  - `100/100`：已完成批次/总批次。\n",
    "  - `[00:30<00:00]`：已用时间/剩余时间。\n",
    "  - `3.33it/s`：迭代速度（每秒处理的批次）。\n",
    "  - `loss=0.42, acc=0.87`：通过 `set_postfix` 添加的动态指标。\n",
    "\n",
    "\n",
    "### **四、常见参数**\n",
    "| 参数          | 作用                                                                 |\n",
    "|---------------|----------------------------------------------------------------------|\n",
    "| `desc`        | 设置进度条前缀描述（如 `desc=\"Training\"`）。                          |\n",
    "| `total`       | 指定总迭代次数（若无法从迭代器推断）。                                |\n",
    "| `leave`       | 训练结束后是否保留进度条（`True` 或 `False`）。                       |\n",
    "| `position`    | 进度条在终端中的垂直位置（整数）。                                    |\n",
    "| `unit`        | 迭代单位（如 `unit=\"batch\"`）。                                       |\n",
    "| `postfix`     | 在进度条右侧显示额外信息（如损失值、准确率）。                        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8256373f",
   "metadata": {},
   "source": [
    "## Tensor.detach()\n",
    "\n",
    "在 PyTorch 中，detach() 方法用于从计算图中分离出一个张量，创建一个新的、不参与梯度计算的张量。这在需要获取张量的数值但不希望影响反向传播时非常有用。以下是详细解释：\n",
    "一、detach() 的核心作用\n",
    "- 切断梯度流动：分离后的张量不再参与梯度计算，其梯度不会传播回原始张量。\n",
    "- 内存优化：在不需要梯度的地方使用 detach()，可以减少计算图的内存占用。\n",
    "- 数值提取：常用于将张量的数值用于日志记录、可视化或非梯度计算。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5d669c",
   "metadata": {},
   "source": [
    "## weight_decay\n",
    "\n",
    "在深度学习中，**`weight_decay`（权重衰减）** 是一种正则化技术，用于防止模型过拟合并提高泛化能力。它通过在损失函数中添加对模型权重的惩罚项，限制模型学习过于复杂的模式。以下是关于 `weight_decay` 的详细解释：\n",
    "\n",
    "\n",
    "### **一、核心作用：抑制过拟合**\n",
    "`weight_decay` 的本质是 **L2 正则化**，其作用是：\n",
    "1. **限制权重大小**：防止模型权重变得过大，避免对训练数据的微小波动过于敏感。\n",
    "2. **简化模型复杂度**：促使模型学习更简单、更泛化的模式，减少对噪声的拟合。\n",
    "3. **改善梯度特性**：在深层网络中，较小的权重有助于缓解梯度消失或爆炸问题。\n",
    "\n",
    "\n",
    "### **二、数学原理**\n",
    "标准的损失函数为：\n",
    "```\n",
    "Loss = 数据损失（如交叉熵）\n",
    "```\n",
    "\n",
    "加入 `weight_decay` 后，损失函数变为：\n",
    "```\n",
    "Loss = 数据损失 + (λ/2) * Σ(w²)\n",
    "```\n",
    "- **λ**：权重衰减系数（如 0.0001），控制惩罚力度。\n",
    "- **Σ(w²)**：所有模型权重的平方和。\n",
    "\n",
    "\n",
    "### **三、优化过程中的效果**\n",
    "在梯度下降更新时，权重衰减等价于在每次参数更新时对权重进行“衰减”：\n",
    "```python\n",
    "# 标准梯度下降更新\n",
    "w = w - learning_rate * ∂Loss/∂w\n",
    "\n",
    "# 加入 weight_decay 后的更新\n",
    "w = w - learning_rate * (∂Loss/∂w + λ * w)\n",
    "```\n",
    "**直观理解**：每次更新时，权重会向零的方向“收缩”一小部分，因此也被称为 **权重衰减**。\n",
    "\n",
    "\n",
    "### **四、在 PyTorch 中的使用**\n",
    "在优化器中设置 `weight_decay` 参数（如 Adam、SGD）：\n",
    "```python\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "```\n",
    "\n",
    "\n",
    "### **五、参数选择建议**\n",
    "- **典型值**：通常在 `1e-5` 到 `1e-2` 之间，需通过验证集调优。\n",
    "- **过大的 `weight_decay`**：会导致权重被过度抑制，模型欠拟合。\n",
    "- **过小的 `weight_decay`**：正则化效果不明显，可能过拟合。\n",
    "- **与学习率的关系**：`weight_decay` 应与学习率协同调整，例如学习率较大时，`weight_decay` 也可适当增大。\n",
    "\n",
    "\n",
    "### **六、与其他正则化方法的对比**\n",
    "| **方法**         | **作用机制**                          | **特点**                              |\n",
    "|------------------|-----------------------------------|-----------------------------------|\n",
    "| **Dropout**      | 随机丢弃神经元，减少神经元间依赖              | 适用于全连接层，训练时随机应用                 |\n",
    "| **L1 正则化**    | 添加权重绝对值之和（Σ\\|w\\|）               | 产生稀疏权重（许多权重为0），可用于特征选择        |\n",
    "| **L2 正则化（Weight Decay）** | 添加权重平方和（Σw²）                | 平滑权重分布，防止过拟合，计算效率更高           |\n",
    "| **Batch Normalization** | 归一化输入分布，减少内部协变量偏移         | 加速训练，本身有一定正则化效果               |\n",
    "\n",
    "\n",
    "### **七、应用场景**\n",
    "1. **大规模数据集**：当训练数据有限时，过拟合风险高，`weight_decay` 尤为重要。\n",
    "2. **复杂模型**：参数较多的模型（如深度 CNN、Transformer）易过拟合，需使用 `weight_decay`。\n",
    "3. **预训练模型**：微调预训练模型时，较小的 `weight_decay`（如 `1e-5`）可保持模型泛化能力。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4480da9",
   "metadata": {},
   "source": [
    "## DataLoader\n",
    "\n",
    "`DataLoader` 是 PyTorch 中用于批量加载数据的核心工具，它提供了高效的数据加载和处理流程。下面详细解释其用法和参数：\n",
    "\n",
    "\n",
    "### **一、核心功能**\n",
    "1. **批量处理**：将数据集分成多个小批次（batches），便于模型训练。\n",
    "2. **并行加载**：使用多线程加速数据读取，提高训练效率。\n",
    "3. **数据打乱**：在每个 epoch 随机打乱数据，增强模型泛化能力。\n",
    "4. **内存优化**：支持内存页锁定（pin memory）和数据预取，加速数据传输到 GPU。\n",
    "\n",
    "\n",
    "### **二、参数详解**\n",
    "```python\n",
    "train_loader = DataLoader(\n",
    "    train_set,                   # 数据集对象\n",
    "    batch_size=config[\"batch_size\"],  # 批次大小\n",
    "    shuffle=True,                # 是否打乱数据\n",
    "    num_workers=0,               # 并行加载的进程数\n",
    "    pin_memory=True,             # 是否使用内存页锁定\n",
    "    # 其他可选参数...\n",
    ")\n",
    "```\n",
    "\n",
    "#### **1. `dataset`**\n",
    "- **类型**：`torch.utils.data.Dataset` 对象（如 `ImageFolder`、自定义 Dataset）。\n",
    "- **作用**：提供数据的访问接口，需实现 `__len__` 和 `__getitem__` 方法。\n",
    "\n",
    "#### **2. `batch_size`**\n",
    "- **作用**：每个批次加载的样本数。\n",
    "- **示例**：`batch_size=32` 表示每次加载 32 个样本。\n",
    "- **影响**：\n",
    "  - 较大的批次：更充分利用 GPU 并行计算，但内存消耗大。\n",
    "  - 较小的批次：训练更稳定，适合小内存设备，但可能降低训练速度。\n",
    "\n",
    "#### **3. `shuffle`**\n",
    "- **作用**：每个 epoch 开始时是否随机打乱数据。\n",
    "- **典型场景**：\n",
    "  - **训练集**：通常设为 `True`，避免模型学习样本顺序。\n",
    "  - **验证/测试集**：通常设为 `False`，方便结果复现。\n",
    "\n",
    "#### **4. `num_workers`**\n",
    "- **作用**：使用多少个子进程并行加载数据。\n",
    "- **默认值**：`0` 表示在主进程中加载数据。\n",
    "- **推荐设置**：\n",
    "  - GPU 训练时：设为 `2-4`（根据 CPU 核心数调整）。\n",
    "  - 内存有限时：设为 `0` 避免内存溢出。\n",
    "\n",
    "#### **5. `pin_memory`**\n",
    "- **作用**：是否将数据提前锁定到 CUDA 固定内存中，加速 CPU 到 GPU 的数据传输。\n",
    "- **适用场景**：\n",
    "  - 数据需传输到 GPU 时（如训练），设为 `True`。\n",
    "  - 仅在 CPU 上运行时，设为 `False`。\n",
    "\n",
    "\n",
    "### **三、其他常用参数**\n",
    "| 参数            | 作用                                                                 |\n",
    "|-----------------|----------------------------------------------------------------------|\n",
    "| `drop_last`     | 当样本数不能被 `batch_size` 整除时，是否丢弃最后一个不完整的批次。   |\n",
    "| `sampler`       | 自定义采样策略（如加权采样、平衡采样）。                              |\n",
    "| `collate_fn`    | 自定义数据合并函数（如处理变长序列）。                                |\n",
    "| `persistent_workers` | 训练结束后是否保留数据加载进程（减少进程创建开销）。                 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23db2e6",
   "metadata": {},
   "source": [
    "## soft vote\n",
    "\n",
    "这段代码实现了一个加权软投票(weighted soft voting)集成策略，将多个数据加载器的预测结果融合为最终预测。让我详细解释这个过程：\n",
    "\n",
    "### 1. 初始化合并数组\n",
    "```python\n",
    "pred_arr = np.zeros(loader_pred_list[0].shape)\n",
    "```\n",
    "- `loader_pred_list` 是一个列表，包含每个数据加载器的预测结果\n",
    "- `loader_pred_list[0].shape` 获取第一个数据加载器的预测形状，通常是 `(样本数, 类别数)`\n",
    "- `np.zeros()` 创建一个全零数组，用于累积所有数据加载器的预测结果\n",
    "\n",
    "### 2. 累积所有预测\n",
    "```python\n",
    "for pred_arr_t in loader_pred_list:\n",
    "    pred_arr += pred_arr_t\n",
    "```\n",
    "- 遍历每个数据加载器的预测结果 `pred_arr_t`\n",
    "- 将它们累加到 `pred_arr` 中\n",
    "- 最终 `pred_arr` 包含了所有数据加载器预测结果的总和\n",
    "\n",
    "### 3. 加权软投票计算\n",
    "```python\n",
    "soft_vote_prediction = np.argmax(0.5 * pred_arr / len(loader_pred_list) + 0.5 * pred_arr_list[-1], axis=1)\n",
    "```\n",
    "这是最关键的部分，让我分步解释：\n",
    "\n",
    "#### 3.1 第一部分：平均预测\n",
    "```python\n",
    "0.5 * pred_arr / len(loader_pred_list)\n",
    "```\n",
    "- `pred_arr / len(loader_pred_list)` 计算所有数据加载器预测的平均值\n",
    "- `0.5 * (...)` 对这个平均值赋予 0.5 的权重\n",
    "\n",
    "#### 3.2 第二部分：最后一个数据加载器的预测\n",
    "```python\n",
    "0.5 * pred_arr_list[-1]\n",
    "```\n",
    "- `pred_arr_list[-1]` 是最后一个数据加载器的预测结果\n",
    "- 同样赋予 0.5 的权重\n",
    "\n",
    "#### 3.3 加权组合\n",
    "```python\n",
    "0.5 * pred_arr / len(loader_pred_list) + 0.5 * pred_arr_list[-1]\n",
    "```\n",
    "- 将两部分预测结果按权重相加\n",
    "- 这种设计意味着：最终预测同时考虑了所有模型的平均意见和最后一个模型的单独意见\n",
    "\n",
    "#### 3.4 类别决策\n",
    "```python\n",
    "np.argmax(..., axis=1)\n",
    "```\n",
    "- 对每个样本，找出得分最高的类别索引\n",
    "- `axis=1` 表示在类别维度上取最大值\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd81451",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LEEDL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
