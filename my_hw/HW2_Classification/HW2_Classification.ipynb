{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9b8a901",
   "metadata": {},
   "source": [
    "# 作业2：音位分类\n",
    "\n",
    "学习目标：\n",
    "* 数据预处理：从原始波形中提取MFCC特征\n",
    "* 分类：使用预提取的MFCC特征执行逐帧音位分类\n",
    "* 熟悉并提高pytorch训练技巧，熟悉pytorch模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6ce2e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\n"
     ]
    }
   ],
   "source": [
    "# 查看GPU状态\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb434e0a",
   "metadata": {},
   "source": [
    "## 准备数据\n",
    "\n",
    "Helper函数用于预处理来自每个音频的原始MFCC特征的训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dab9d8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from numpy import concat\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_feat(path):\n",
    "    \"\"\" 定义导入feature函数 \"\"\"\n",
    "    feat = torch.load(path)\n",
    "    return feat\n",
    "\n",
    "def shift(x, n):\n",
    "    \"\"\" 简单理解就是\n",
    "            n < 0\n",
    "            11112\n",
    "            11123\n",
    "            11234\n",
    "            12345\n",
    "\n",
    "            12345\n",
    "\n",
    "            12345\n",
    "            23455\n",
    "            34555\n",
    "            45555\n",
    "            n > 0\n",
    "    \"\"\"\n",
    "    if n < 0:\n",
    "        left = x[0].repeat(-n, 1)\n",
    "        right = x[:n]\n",
    "    elif n > 0:\n",
    "        right = x[-1].repeat(n, 1)\n",
    "        left = x[n:]\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "    return torch.cat((left, right), dim=0)\n",
    "\n",
    "def concat_feat(x, concat_n):\n",
    "    \"\"\" 将前后的特征联系到一起，如 concat_n = 11 则前后都接5 \"\"\"\n",
    "    assert concat_n % 2 == 1 # n必须为奇数\n",
    "    if concat_n < 2:\n",
    "        return x\n",
    "    seq_len, feature_dim = x.size(0), x.size(1)\n",
    "    x = x.repeat(1, concat_n) # 先把特征维度复制出原来长度的concat_n倍，用于后续shift操作\n",
    "    x = x.view(seq_len, concat_n, feature_dim).permute(1, 0, 2) # (concat_n, seq_len, feature)\n",
    "    mid = (concat_n // 2)\n",
    "    for r_idx in range(1, mid + 1):\n",
    "        x[mid + r_idx, :] = shift(x[mid + r_idx], r_idx)\n",
    "        x[mid - r_idx, :] = shift(x[mid - r_idx], -r_idx)\n",
    "    \n",
    "    return x.permute(1, 0, 2).view(seq_len, concat_n * feature_dim)\n",
    "\n",
    "def preprocess_data(split, feat_dir, phone_path, concat_nframes, train_ratio=0.8, train_val_seed=1337):\n",
    "    \"\"\" 数据预处理函数 \n",
    "            return: 返回值 X 代表处理好的数据，若不concat则为39，否则为 39*concat_n\n",
    "    \"\"\"\n",
    "    class_num = 41 # 类别已经处理好了，不需要更改\n",
    "    mode = \"train\" if (split == \"train\" or split == \"val\") else \"test\"\n",
    "\n",
    "    # train/val dataset 读取 label\n",
    "    label_dict = {}\n",
    "    if mode != \"test\":\n",
    "        phone_file = open(os.path.join(phone_path, \"train_labels.txt\")).readlines()\n",
    "        for line in phone_file:\n",
    "            line = line.strip(\"\\n\").split(\" \")\n",
    "            label_dict[line[0]] = [int(p) for p in line[1:]]\n",
    "\n",
    "    if split == \"train\" or split == \"val\":\n",
    "        # 划分 train 和 val\n",
    "        temp_list = open(os.path.join(phone_path, \"train_split.txt\")).readlines()\n",
    "        random.seed(train_val_seed)\n",
    "        random.shuffle(temp_list)\n",
    "        train_val_split_positon = int(len(temp_list) * train_ratio)\n",
    "        temp_list = temp_list[:train_val_split_positon] if split == \"train\" else temp_list[train_val_split_positon:]\n",
    "    elif split == \"test\":\n",
    "        temp_list = open(os.path.join(phone_path, \"test_split.txt\"))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid 'split' argument for dataset: PhoneDataset!\")\n",
    "\n",
    "    temp_list = [line.strip(\"\\n\") for line in temp_list]\n",
    "    print(\"[Dataset] - # phone classes: \" + str(class_num) + \", number of utterances for \" + split + \": \" + str(len(temp_list)))\n",
    "\n",
    "    max_len = 3000000\n",
    "    X = torch.empty(max_len, 39 * concat_nframes) # 第1维是按照题目提示处理为 39 * concat_nframes\n",
    "    if mode != \"test\":\n",
    "        y = torch.empty(max_len, dtype=torch.long) # 只需要一个维度按照idx存储label即可\n",
    "\n",
    "    idx = 0\n",
    "    for i, fname in tqdm(enumerate(temp_list)):\n",
    "        feat = load_feat(os.path.join(feat_dir, mode, f\"{fname}.pt\")) # 这些文件已经在课程给的数据中处理好了\n",
    "        cur_len = len(feat)\n",
    "        feat = concat_feat(feat, concat_nframes)\n",
    "        if mode != \"test\":\n",
    "            label = torch.LongTensor(label_dict[fname])\n",
    "        \n",
    "        X[idx: idx + cur_len, :] = feat\n",
    "        if mode != \"test\":\n",
    "            y[idx: idx + cur_len] = label\n",
    "        \n",
    "        idx += cur_len\n",
    "\n",
    "    # 截断，只保留有效数据\n",
    "    X = X[:idx, :]\n",
    "    if mode != \"test\":\n",
    "        y = y[:idx]\n",
    "\n",
    "    print(f\"[INFO] {split} set\")\n",
    "    print(X.shape)\n",
    "    if mode != \"test\":\n",
    "        print(y.shape)\n",
    "        return X, y\n",
    "    else:\n",
    "        return X\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e77c05",
   "metadata": {},
   "source": [
    "## 定义数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e95c8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# 导入数据集\n",
    "from torch.utils.data import Dataset\n",
    "# 导入数据加载工具Dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class LibriDataset(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.data = X\n",
    "        if y is not None:\n",
    "            # training/val dataset\n",
    "            self.label = torch.LongTensor(y)\n",
    "        else:\n",
    "            # testing dataset\n",
    "            self.label = None\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.label is not None:\n",
    "            return self.data[idx], self.label[idx]\n",
    "        else:\n",
    "            return self.data[idx]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9118ae3",
   "metadata": {},
   "source": [
    "## 神经网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32a1a85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "    \n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=41, hidden_layers=1, hidden_dim=256):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            BasicBlock(input_dim, hidden_dim),\n",
    "            # *[] 是 Python 的 解包（unpacking） 语法，用于将列表中的元素作为独立参数传递给函数或类。\n",
    "            *[BasicBlock(hidden_dim, hidden_dim) for _ in range(hidden_layers)],\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff04844",
   "metadata": {},
   "source": [
    "## 超参数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63c6bd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data parameters\n",
    "# 用于数据处理时的参数\n",
    "concat_nframes = 1   # 要链接的帧数\n",
    "train_ratio = 0.8\n",
    "\n",
    "# training parameters\n",
    "seed = 0\n",
    "batch_size = 512\n",
    "num_epoch = 5\n",
    "learning_rate = 0.0001\n",
    "model_path = \"./model.ckpt\"\n",
    "\n",
    "# model parameters\n",
    "input_dim = 39 * concat_nframes\n",
    "hidden_layers = 1\n",
    "hidden_dim = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b9e35c",
   "metadata": {},
   "source": [
    "## 准备数据与模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53249358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset] - # phone classes: 41, number of utterances for train: 3428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3428it [00:02, 1584.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] train set\n",
      "torch.Size([2116368, 39])\n",
      "torch.Size([2116368])\n",
      "[Dataset] - # phone classes: 41, number of utterances for val: 858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "858it [00:00, 1633.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val set\n",
      "torch.Size([527790, 39])\n",
      "torch.Size([527790])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 引入gc模块进行垃圾回收\n",
    "import gc\n",
    "\n",
    "# 预处理数据\n",
    "train_X, train_y = preprocess_data(split=\"train\", feat_dir=\"./libriphone/feat\", phone_path=\"./libriphone\", concat_nframes=concat_nframes, train_ratio=train_ratio)\n",
    "val_X, val_y = preprocess_data(split=\"val\", feat_dir=\"./libriphone/feat\", phone_path=\"./libriphone\", concat_nframes=concat_nframes, train_ratio=train_ratio)\n",
    "\n",
    "# 导入数据\n",
    "train_set = LibriDataset(train_X, train_y)\n",
    "val_set = LibriDataset(val_X, val_y)\n",
    "\n",
    "# 删除原始数据以节省内存\n",
    "del train_X, train_y, val_X, val_y\n",
    "gc.collect()\n",
    "\n",
    "# 利用 dataloader 加载数据\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7b8b811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# 检查当前是否有可用GPU，俺是mac当然没有\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b2aa1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 固定随机种子\n",
    "def same_seeds(seed): \n",
    "    # 固定随机种子（CPU）\n",
    "    torch.manual_seed(seed) \n",
    "    # 固定随机种子（GPU)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed) # 为当前GPU设置\n",
    "        torch.cuda.manual_seed_all(seed)  # 为所有GPU设置\n",
    "    np.random.seed(seed)  # 保证后续使用random函数时，产生固定的随机数\n",
    "    torch.backends.cudnn.benchmark = False # GPU、网络结构固定，可设置为True\n",
    "    torch.backends.cudnn.deterministic = True # 固定网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30889b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 固定随机种子\n",
    "same_seeds(seed)\n",
    "\n",
    "# 创建模型、定义损失函数和优化器\n",
    "model = Classifier(input_dim=input_dim, output_dim=41, hidden_layers=hidden_layers, hidden_dim=hidden_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea142ea",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b5e5106",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2681011f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4134/4134 [00:07<00:00, 538.15it/s]\n",
      "100%|██████████| 1031/1031 [00:01<00:00, 867.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001/005] Train Acc: 0.421902 Loss: 2.08666 | Val Acc: 0.440529\n",
      "saving model with acc 0.440529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4134/4134 [00:07<00:00, 556.69it/s]\n",
      "100%|██████████| 1031/1031 [00:01<00:00, 871.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[002/005] Train Acc: 0.449017 Loss: 1.9345 | Val Acc: 0.449728\n",
      "saving model with acc 0.449728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4134/4134 [00:07<00:00, 558.10it/s]\n",
      "100%|██████████| 1031/1031 [00:01<00:00, 896.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[003/005] Train Acc: 0.455059 Loss: 1.90437 | Val Acc: 0.453906\n",
      "saving model with acc 0.453906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4134/4134 [00:07<00:00, 556.42it/s]\n",
      "100%|██████████| 1031/1031 [00:01<00:00, 871.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[004/005] Train Acc: 0.458414 Loss: 1.88801 | Val Acc: 0.456062\n",
      "saving model with acc 0.456062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4134/4134 [00:07<00:00, 559.59it/s]\n",
      "100%|██████████| 1031/1031 [00:01<00:00, 848.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[005/005] Train Acc: 0.460793 Loss: 1.87644 | Val Acc: 0.457826\n",
      "saving model with acc 0.457826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0.0\n",
    "for epoch in range(num_epoch):\n",
    "    train_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    val_loss = 0.0\n",
    "\n",
    "    # training\n",
    "    model.train() # 设置模型位训练模式\n",
    "    for i, batch in enumerate(tqdm(train_loader)):\n",
    "        features, labels = batch\n",
    "        features.to(device)\n",
    "        labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, train_pred = torch.max(outputs, dim=1) # 获取概率最高的类的索引\n",
    "        # tensor.detach重新在一块内存上保存tensor，数值关联，但是不涉及到剃度计算，避免错误的梯度回传\n",
    "        # 不过此处计算发生在反向传播之后，梯度已经不需要\n",
    "        train_acc += (train_pred.detach() == labels.detach()).sum().item()\n",
    "        train_loss += loss.item() # 将loss转化为数值\n",
    "\n",
    "    # validing\n",
    "    if len(val_set) > 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(tqdm(val_loader)):\n",
    "                features, labels = batch\n",
    "                features.to(device)\n",
    "                labels.to(device)\n",
    "\n",
    "                outputs = model(features)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                _, val_pred = torch.max(outputs, dim=1)\n",
    "                # 后续需要打印结果，gpu上的tensor无法打印，需要移动到cpu转为numpy等可以打印的数据形式\n",
    "                # 不过通过 .item() 转为 python 的基本数据类型了，可以直接打印，所以不需要 .cpu() 也可以\n",
    "                val_acc += (val_pred.cpu() == labels.cpu()).sum().item()\n",
    "                val_loss += loss.item()\n",
    "\n",
    "            print(\"[{:03d}/{:03d}] Train Acc: {:3.6} Loss: {:3.6} | Val Acc: {:3.6f}\".format(\n",
    "                epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader), val_acc/len(val_set), val_loss/len(val_loader)\n",
    "            ))\n",
    "\n",
    "            # 如果模型获得提升，在此阶段保存模型\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                print(\"saving model with acc {:3.6f}\".format(best_acc/len(val_set)))\n",
    "    else:\n",
    "        print(\"[{:03d}/{:03d}] Train Acc: {:3.6} Loss: {:3.6}\".format(\n",
    "            epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader)\n",
    "        ))\n",
    "    \n",
    "    # 如果结束验证，则保留最后一个epoch得到的模型\n",
    "    if len(val_set) == 0:\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(\"saving mdoel at last epoch\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93c6f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_loader, val_loader\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0742075e",
   "metadata": {},
   "source": [
    "## 测试\n",
    "创建测试数据集，并从保存的检查点加载模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27f5887d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset] - # phone classes: 41, number of utterances for test: 1078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1078it [00:00, 1569.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] test set\n",
      "torch.Size([646268, 39])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 载入数据\n",
    "test_X = preprocess_data(split=\"test\", feat_dir=\"./libriphone/feat\", phone_path=\"./libriphone\", concat_nframes=concat_nframes)\n",
    "test_set = LibriDataset(test_X, None)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4fef5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载已经训练好的模型\n",
    "model = Classifier(input_dim=input_dim, output_dim=41, hidden_layers=hidden_layers, hidden_dim=hidden_dim).to(device)\n",
    "model.load_state_dict(torch.load(\"./model.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b99b8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1263/1263 [00:01<00:00, 1223.60it/s]\n"
     ]
    }
   ],
   "source": [
    "test_acc = 0.0\n",
    "test_lengths = 0\n",
    "pred = np.array([], dtype=np.int32)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(tqdm(test_loader)):\n",
    "        features = batch\n",
    "        features = features.to(device)\n",
    "\n",
    "        outputs = model(features)\n",
    "\n",
    "        _, test_pred = torch.max(outputs, dim=1)\n",
    "        # 把预测结果移动到 cpu 上，转为 numpy 数组，然后使用 np.concatenate() 进行合并\n",
    "        pred = np.concatenate((pred, test_pred.cpu().numpy()), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9b3d47",
   "metadata": {},
   "source": [
    "## 将预测结果写入CSV文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3643f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"prediction.csv\", \"w\") as f:\n",
    "    f.write(\"Id, Class\\n\")\n",
    "    for i, y in enumerate(pred):\n",
    "        f.write(\"{}, {}\\n\".format(i, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60b5255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LEEDL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
